# Neo4j Configuration
NEO4J_URI=bolt://localhost:7687
NEO4J_USER=neo4j
NEO4J_PASSWORD=password
NEO4J_DATABASE=neo4j

# Server Configuration
USE_SSE=false      # Set to true for Server-Sent Events, false for stdio mode
PORT=8080          # Port for HTTP server mode
LOG_LEVEL=info     # Logging level (debug, info, warn, error)

# Embedding Configuration
# Set EMBEDDER_PROVIDER to one of: none, openai, huggingface, ollama, azure, azure_openai, lmstudio, vertexai, gemini, mistral
EMBEDDER_PROVIDER=none    # Set to 'none' to disable embeddings

# OpenAI Embedding Configuration
# EMBEDDER_PROVIDER=openai
# OPENAI_API_KEY=your_openai_api_key
# OPENAI_API_BASE=                      # Optional: Custom OpenAI API base URL
# EMBEDDING_MODEL=text-embedding-3-small
# EMBEDDING_DIMS=1536                   # Dimensions of the embedding model (varies by model)

# Hugging Face Configuration
# EMBEDDER_PROVIDER=huggingface
# HUGGINGFACE_API_KEY=your_huggingface_api_key
# HUGGINGFACE_MODEL=sentence-transformers/all-mpnet-base-v2
# HUGGINGFACE_MODEL_KWARGS={"device":"cpu"}  # Optional: Custom model parameters
# EMBEDDING_DIMS=768

# Ollama Configuration
# EMBEDDER_PROVIDER=ollama
# OLLAMA_MODEL=llama2
# OLLAMA_BASE_URL=http://localhost:11434  # Optional: Custom Ollama API URL
# EMBEDDING_DIMS=4096

# Azure OpenAI Configuration
# EMBEDDER_PROVIDER=azure_openai
# AZURE_MODEL=text-embedding-3-small
# EMBEDDING_AZURE_OPENAI_API_KEY=your_azure_api_key
# AZURE_API_KEY=your_azure_api_key      # Alternative to EMBEDDING_AZURE_OPENAI_API_KEY
# EMBEDDING_AZURE_ENDPOINT=https://your-resource.openai.azure.com
# AZURE_ENDPOINT=https://your-resource.openai.azure.com  # Alternative to EMBEDDING_AZURE_ENDPOINT
# EMBEDDING_AZURE_DEPLOYMENT=your-deployment-name
# AZURE_DEPLOYMENT=your-deployment-name  # Alternative to EMBEDDING_AZURE_DEPLOYMENT
# EMBEDDING_AZURE_API_VERSION=2023-05-15
# EMBEDDING_AZURE_DEFAULT_HEADERS={"CustomHeader":"your-custom-header"}
# EMBEDDING_DIMS=1536

# LM Studio Configuration
# EMBEDDER_PROVIDER=lmstudio
# LMSTUDIO_BASE_URL=http://localhost:1234
# EMBEDDING_DIMS=4096

# VertexAI (Google Cloud) Configuration
# EMBEDDER_PROVIDER=vertexai
# VERTEXAI_MODEL=text-embedding-004
# GOOGLE_APPLICATION_CREDENTIALS=/path/to/your/credentials.json
# VERTEX_PROJECT=your-google-cloud-project-id
# VERTEX_LOCATION=us-central1
# VERTEXAI_MEMORY_ADD_EMBEDDING_TYPE=RETRIEVAL_DOCUMENT
# EMBEDDING_DIMS=256

# Gemini Configuration
# EMBEDDER_PROVIDER=gemini
# GEMINI_MODEL=models/text-embedding-004
# GOOGLE_API_KEY=your_google_api_key
# EMBEDDING_DIMS=768

# Mistral Configuration
# EMBEDDER_PROVIDER=mistral
# MISTRAL_MODEL=mistral-embed
# MISTRAL_API_KEY=your_mistral_api_key
# EMBEDDING_DIMS=1024 